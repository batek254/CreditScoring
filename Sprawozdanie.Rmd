---
title: "Predicting Result"
author: "Mateusz Jalocha"
date: "26 stycznia 2019"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	include = FALSE
)
library(textfeatures)
library(tidyverse)
library(itunesr)
library(corrplot) #Macierz korelacji
library(gridExtra) #Tabelki
library(flextable)
library(officer)
library(kableExtra)
library(ltm)
library(randomForest)
library(ggplot2)
library(mlr)
library(kableExtra)
library(dplyr)
library(GGally)
library(corrplot)
library("naniar")
library("forecast")
library("missForest")
library("rlist")
library("readr")
library("bnstruct")
library("haven")
library("VIM")
library("xgboost")
library("gbm")
library("caret")
library("class")
library("e1071")
library("MASS")
library("adabag")
library("ipred")
library("missForest")
library("Matrix")
library("data.table")
library("mice")
```

```{r, echo = FALSE, include = FALSE}
##########################Funkcje
##Funkcja do odpalania metod
loan_predict<-function(trainset,testset,method,arg_list=NULL){
  
  eval(parse(text = "rf <- randomForest"))
  eval(parse(text = "nb <- naiveBayes"))
  eval(parse(text = "knn <- knn3"))
  eval(parse(text = "logit <- glm"))

  eval(parse(text = paste0("model_construct <- ", method)))
  model<-do.call(model_construct, c(list(formula=Loan_Status~.,data=trainset),arg_list))
  
  pred_test <- predict(model, newdata = testset)
  if (method=="lda"||method=="qda") {
    pred_test <- predict(model, newdata = testset)$class 
  }
  if (method=="gbm") { 
    best.iter <- gbm.perf(model, method = "cv")[1]
    pred_test<-predict(model,testset,n.trees=best.iter)
    pred_test<-round(pred_test,0)
  }
  if (method=="logit"||method=="knn") { 
    pred_test<-predict(model,testset,type=if(method=="logit") {type <- "response" })
    if (method=="knn") { pred_test<-pred_test[,2] }
    pred_test<-ifelse(pred_test > 0.5,"1", "0")
  }
  pred_test = as.numeric(pred_test)
  u <- union(round(pred_test), testset$Loan_Status)
  conf_test <- table(factor(round(pred_test), u), factor(testset$Loan_Status, u))
  acc_test <-confusionMatrix(conf_test)$overall['Accuracy']
  
  pred_train <- predict(model, newdata = trainset)
  if (method=="lda"||method=="qda") { 
    pred_train <- predict(model, newdata = trainset)$class
  }
  if (method=="gbm") { 
    best.iter <- gbm.perf(model, method = "cv")[1]
    pred_train<-predict(model,trainset,n.trees=best.iter)
    pred_train<-round(pred_train,0)
  }
  if (method=="logit"||method=="knn") { 
    pred_train<-predict(model,trainset,type=if(method=="logit") {type <- "response" })
    if (method=="knn") { pred_train<-pred_train[,2] }
    pred_train<-ifelse(pred_train > 0.5,"1", "0")
  }
  pred_train = as.numeric(pred_train)
  u <- union(round(pred_train), trainset$Loan_Status)
  conf_train <- table(factor(round(pred_train), u), factor(trainset$Loan_Status, u))
  acc_train <-confusionMatrix(conf_train)$overall['Accuracy']
  
  return(list("method"=method,"accuracy_test"=as.numeric(acc_test),"accuracy_train"=as.numeric(acc_train),"confusion_matrix_test"=conf_test))
}

#cross-validation prediction
cv_pred <- function(n_times,wszystkie_zbiory,method,arg_list=NULL)
{
  acc_list = list()
  for(j in 1:length(wszystkie_zbiory)) {
    acc = 0
    set = wszystkie_zbiory[[j]]
    #Randomly shuffle the data
    set.seed(123)
    set<-set[sample(nrow(set)),]
    #Create 10 equally size folds
    folds <- cut(seq(1,nrow(set)),breaks=n_times,labels=FALSE)
    
    #Perform 10 fold cross validation
    for(i in 1:n_times){
      set.seed(123)
      #Segement your data by fold using the which() function 
      testIndexes <- which(folds==i,arr.ind=TRUE)
      testset <- set[testIndexes, ]
      trainset <- set[-testIndexes, ]
      
      wynik = loan_predict(trainset,testset,method,arg_list=arg_list)
      acc = acc + wynik[[2]]
    }
    
    acc_list[[j]] <- acc/n_times
  }
  return(acc_list)
}


##Funkcja dowyswietlania
frame_func <- function(frame) {
  big_b <- fp_border(color="gray70", width = 1)
  std_b <- fp_border(color="gray70")
  
  frame %>% 
    regulartable() %>% 
    autofit() %>% 
    width(width = 2) %>% 
    fontsize(part = "all", size = 15) %>% 
    align(part = "all", align = "center") %>% 
    vline(border = big_b, part = "all" ) %>%
    vline_left(border = big_b, part = "all" ) %>% 
    vline_right(border = big_b, part = "all" ) %>% 
    hline(border = std_b ) %>% 
    hline_bottom(border = big_b, part = "all") %>% 
    hline_top(border = big_b, part = "all" ) %>%
    font(part = "all",fontname = "Times") %>% 
    bold(part = "header")
}

```
##1. Wstęp
Niniejszy projekt zostal zrobiony w oparciu o konkurs odbywajacy sie na stronie https://www.analyticsvidhya.com/. Do rozwiazania jest praktyczny problem przewidywania czy osoba starajaca sie o pozyczke w banku ja otrzyma. Poprzez analize metod uzupelniania brakujacych danych, tworzenia nowych zmiennych oraz sprawdzenie, ktora z metod predykcyjnych okaze sie najbardziej skuteczna, zostania wybrane metody oraz zmienne, dzieki ktorym skuteczonsc przewidywania bedzie najwieksza. Uzytymi metodami uzupelniania danych w pracy sa algorytmy: KNN, Miss Forest oraz MICE. Jesli chodzi o metody predykcji to w pracy zostaly zastosowane: Random Forest, GBM, Regresja logistyczna, QDA, LDA, XGBoost, Boosting, KNN.
###1.1 Przedstawienie danych
```{r, warning=FALSE, message=FALSE}
train2 <- read.csv("train.csv")
summary(train2)
```

Dane train.csv składają się z 614 obserwacji oraz 13 zmiennych:

* <b>Loan_ID</b> - numer identyfikacyjny pożyczki

* <b>Gender</b> - płęć kredytobiorcy

* <b>Married</b> - stan cywilny kredytobiorcy

* <b>Dependents</b> - liczba osób na utrzymaniu

* <b>Education</b> - poziom ukończonej edukacji

* <b>Self_Employed</b> - określa, czy kredytobiorca jest samozatrudniony

* <b>ApplicantIncome</b> - dochody kredytobiorcy

* <b>CoapplicantIncome</b> - poziom dochodów osoby współubiegającej się o kredyt

* <b>LoanAmount</b> - kwota pożyczki

* <b>Loan_Amount_Term</b> - czas na jaki brana jest pożyczka

* <b>Credit_History</b> - czy historia kredytowa kredytobiorcy jest pozytywna

* <b>Poperty_Area</b> - teren na jakim znajduje się nieruchomość

* <b>Loan_Status</b> - decyduje o pozytywnym lub negatywny rozpatrzeniu wniosku o kredyt, osiaga wartosc 1 dla negatywnego rozpatrzenia wniosku.


###1.2 Wstępna obróbka danych
```{r, warning=FALSE, message=FALSE}
#Wczytanie danych
train2 <- read.csv('train.csv')
train2$Loan_Status <- ifelse(train2$Loan_Status == "N", 1, 0)
head(train2) %>% frame_func()
```

Po wczytaniu danych napotkano pierwszy problem, mianowicie w przypadku zmiennych kategorycznych wartosci puste sa oznaczane jako pusty string, nie zas jako NA. Jednak dla sytuacji kiedy zmienna Married przyjmuje jako wartosc pustego stringa to kredyt zawsze był udzielany, a jesli zmienna Self Employed przyjmuje taka wartosc i przy okazji zmienna Credit History przyjmuje wartosc NA to w 5 na 6 przypadkow kredyt nie zostal udzielony.

<center><b>Married empty</b></center>
```{r, warning=FALSE, message=FALSE}
Married_Empty = as.data.frame(table(train2$Loan_Status[train2$Married == ""]))
colnames(Married_Empty)[1] = "Loan_Status"
frame_func(Married_Empty)
```

<center><b>Self Emplyed empty and Credit History NA</b></center>
```{r, warning=FALSE, message=FALSE}
SEmployed_naHist = as.data.frame(table(train2$Loan_Status[train2$Self_Employed == ""&is.na(train2$Credit_History)]))
colnames(SEmployed_naHist)[1] = "Loan_Status"
frame_func(SEmployed_naHist)
```

 Na podstawie tych wynikow powstaly nowe zmienne:

* <b>Married_Empty</b> - Zmienna binarna, przyjmujaca 1 dla sytuacji jesli zmienna Married przyjmowala wartosc pustego stringa.

* <b>SEmployed_naHist</b> - Zmienna binarna, przyjmujaca 1 dla sytuacji jesli zmienna Self Employed przyjmowala wartosc pustego stringa, a Credit History wartosc NA.


```{r,fig.align = 'center',out.extra='angle=90', fig.height=4}
Married_Empty = train2$Married
Married_Empty = ifelse(Married_Empty =="", 1, 0)

SEmployed_naHist = ifelse(train2$Self_Employed =="" & is.na(train2$Credit_History), 1, 0)

train2$Married_Empty = Married_Empty
train2$SEmployed_naHist = SEmployed_naHist
train2$Gender[train2$Gender=='']=NA
train2$Married[train2$Married=='']=NA
train2$Dependents[train2$Dependents=='']=NA
train2$Education[train2$Education=='']=NA
train2$Self_Employed[train2$Self_Employed=='']=NA
train2$Property_Area[train2$Property_Area=='']=NA
train2 <- droplevels(train2)
vis_miss(train2)
```

###1.3 Analiza wizualna
```{r, echo=FALSE, message=FALSE, warning=FALSE}
ggpairs(train2[,-1])
```

Na powyzszym wykresie mozna zauwazyc, ze problem brakujacych danych jest dosyc spory. Niniejsza praca zostanie przeprowadzona przy pomocy wielu metod, ktore probuja sobie poradzic z zagadanieniem brakujacych danych oraz dokladnosci predykcji, aby wyniki okazaly sie odbiegac od rzeczywistosci w jak najmniejszym stopniu

###1.4 Feature Scaling
```{r, echo=FALSE, message=FALSE, warning=FALSE}
data_norm <- normalizeFeatures(train2)
summarizeColumns(data_norm)
```

```{r, warning=FALSE, message=FALSE}

train2_norm <- normalizeFeatures(train2, target = 'Loan_Status')
train2 <- train2_norm

set_knn <- c()
set_knn_test <- c()
knn_nazwa <- c()
set_mf <- c()
set_mf_test <- c()
mf_nazwa <- c()
set_mice <- c()
set_mice_test <- c()
mice_nazwa <- c()
```


```{r, warning=FALSE, message=FALSE}
train = train2
train_NA<-train2[complete.cases(train2),]
set_NA<-train_NA[,-1]

train_knn <- VIM::kNN(train2, variable = c("Gender", "Married", "Dependents","Self_Employed", "LoanAmount", "Loan_Amount_Term", "Credit_History"), k = 6)
set_KNN<-train_knn[,-c(1,16:22)]

train2 <- train2[,c(11,13)]
train_knn <- VIM::kNN(train2, variable = c("Credit_History"), k = 6)
set_Credit<-train_knn[,-3]

lista_dane <- list(set_NA,set_KNN,set_Credit)
train2 = train
```

##2. Uzupelnianie brakujacych danych
Zdecydowalismy sie przeprowadzic badanie w oparciu o 3 bazowe zbiory danych, na ktore skladaja sie: zbior z usunietymi obserwacjami brakujacymi, zbior uzupelnionymi obserwacjami brakujacymi w zbiorze testowym metoda KNN oraz zbior, w ktorym znajduje sie tylko zmienna Credit History. Do wynikow uzyskanych na podstawie zbiorow bazowych bedziemy porownywac wyniki uzyskane na zbiorach, w ktorych uzupelnilismy dane roznymi metodami. W kontekscie uzupelniania danych wybralismy trzy algorytmy, ktore w sposob skuteczny potrafia uzupelniac dane wieloma metodami, do wybranych metod zaliczamy:

* <b>KNN</b> - Pierwsza zastosowana przez nas metoda uzupelniania brakujacych danych jest metoda KNN. Przy tworzeniu zbioru danych manipulowalismy parametrem "k", odpowiedzialnym za liczbe najblizszych sasiadow branych pod uwage. Liczba sasiadow przyjmuje wartosci od 1 do pierwiasta liczby obserwacji, a wiec w tym przypadku 25.

* <b>Miss Forest</b> - Druga metoda uzupelniania danych jest metoda missForest, wykorzystujaca lasy losowe. Przy tworzeniu zbiorow danych zmienialismy liczbe drzew (ntree - przyjmuje wartosci 200 oraz 300), maksymalna liczbe iteracji (maxiter - przyjmujaca wartosc  3) oraz liczbe zmiennych brana pod uwage (mtry - przyjmujaca wartosci od 4 do 9).

* <b>Mice</b> - Ostatnia metoda jest funkcja MICE, ktora wykorzystuje do wstawiania obserwacji wybrana w funkcji metode (do uzytych przez nas naleza: pmm, midastouch, sample, cart, random forest). Do manipulacji wykorzystalismy rozne metody uzupelniania danych oraz piec mozliwych zestawow danych z kazdej iteracji (m).

```{r , include=FALSE}
for (i in 1:round(sqrt(nrow(train2)))){
  train_knn <- VIM::kNN(train2[,-1], variable = c("Gender", "Married", "Dependents","Self_Employed",   "LoanAmount", "Loan_Amount_Term", "Credit_History"), k = i)
  set <- train_knn
  set <- train_knn[,-c(13:19)]
  set_knn<-c(set_knn,list(set))
  
  ###Podzial danych
  set.seed(123)
  train_ind<-sample(1:nrow(train2),floor(0.75*nrow(train2)))
      
  trainset<-train2[train_ind,]
  testset<-train2[-train_ind,]  
  
  train_knn_test <- VIM::kNN(testset[,-1], variable = c("Gender", "Married", "Dependents","Self_Employed",   "LoanAmount", "Loan_Amount_Term", "Credit_History"), k = i)
  set_knn_test<-c(set_knn_test,list(train_knn_test[,-c(15:21)]))
  
  knn_nazwa <- c(knn_nazwa, list(paste("k = ",i)))
}
```

```{r, warning=FALSE, message=FALSE}
for (nt in c(200,300)){
  for (mi in c(3)){
    for (mt in c(4:9)){
      train_miss <- missForest(train2[,-1], ntree = nt, maxiter = mi, mtry=mt)
      set <- train_miss$ximp
      set_mf<-c(set_mf, list(set))
      
      ###Podzial danych
      set.seed(123)
      train_ind<-sample(1:nrow(train2),floor(0.75*nrow(train2)))
      
      trainset<-train2[train_ind,]
      testset<-train2[-train_ind,]  
  
      train_miss_test <- missForest(testset[,-1], ntree = nt, maxiter = mi, mtry=mt)
      set_mf_test<-c(set_mf_test, list(train_miss_test$ximp))
      
      mf_nazwa <- c(mf_nazwa,list(paste0("nt: ",nt," mi: ", mi, " mt: ", mt)))
    }
  }
}
```

```{r, warning=FALSE, message=FALSE}
for (f in c("pmm","sample","cart","rf")){
  for (M in c(1,2,3,4,5)){
    train_mice <- mice(train2[,-1],m=M,method=f,seed = 123,printFlag = FALSE)
    set <- mice::complete(train_mice,M)
    set_mice<-c(set_mice, list(set))
    
    ###Podzial danych
    set.seed(123)
    train_ind<-sample(1:nrow(train2),floor(0.75*nrow(train2)))
      
    trainset<-train2[train_ind,]
    testset<-train2[-train_ind,]  
  
    train_mice_test <- mice(testset[,-1],m=M,method=f,seed = 123,printFlag = FALSE)
    set_mice_test<-c(set_mice_test, list(mice::complete(train_mice_test,M)))
    
    mice_nazwa <- c(mice_nazwa,list(paste0("f: ",f," M: ", M)))
  }
}
```

```{r, warning=FALSE, message=FALSE}
#Po??czenie list z uzupelniania
uzupelnianie_dane = c(set_knn,set_mf,set_mice)
nazwa_atrybutow = c(knn_nazwa,mf_nazwa,mice_nazwa)
nazwa_metody = c((rep(list("KNN"), length(knn_nazwa))), rep(list("Miss Forest"), length(mf_nazwa)), rep(list("Mice"), length(mice_nazwa)))
```

##3. Features Engineering
Podstawa wiekszosci analiz, jest features engineering, ktory polega na tworzeniu nowych zmiennych przy pomocy tych istniejacych. Ma to pomoc przy tworzeniu modeli, zwiekszajac ich skutecznosc predykcji. W przypadku kiedy zmienna endogeniczna jest zmienna kategoryczna, warto zweryfikowac, czy isntnieje roznica w rozkladach nowych zmiennych w zaleznosci od poziomu zmiennej objasnianej. Przedstawienie tworzenia nowych zmiennych zostalo przeprowadzone przy pomocy zbioru z usunietymi brakujacymi obserwacjami, po czym zostanie zastosowane dla wszystkich wzietych pod uwage przy badaniu zbiorow danych.

####3.1 Nowe zmienne
Jako nowe zmienne zostaly utworzone:

* <b>Income</b> - Jest to laczny przychod miesieczny osoby ubiegajacej sie o kredyt oraz poreczyciela.

* <b>Percent_income_of_loan</b> - Procent jaki stanowi miesieczny przychod calej pozyczki.

* <b>Loan_amount_per_month</b> - Kwota pozyczki podzielona przez liczbe miesiecy jej trwania.

* <b>Percent_loan_per_month_income</b> - Procent jaki stanowi kwota pozyczki podzielonej przez liczbe miesiecy jej trwania calego przychodu

* <b>n_pers_income</b> - Liczba osob z osoby ubiegajacej sie o kredyt oraz poreczyciela, ktora posiada doch?d.


####3.2 Charakterystyka nowych zmiennych

<center><b>Kredyt zostal udzielony</b></center>
```{r, echo=FALSE}
feature_eng_set = read.csv('train.csv')
feature_eng_set$Loan_Status <- ifelse(feature_eng_set$Loan_Status == "N", 1, 0)
feature_eng_set = feature_eng_set[complete.cases(feature_eng_set),]

feature_eng_set$Income = (feature_eng_set$ApplicantIncome + feature_eng_set$CoapplicantIncome)
feature_eng_set$n_pers_income = ifelse(feature_eng_set$ApplicantIncome >0 & feature_eng_set$CoapplicantIncome >0, 1, 0)
feature_eng_set$Loan_amout_per_month = (feature_eng_set$LoanAmount * 1000)/feature_eng_set$Loan_Amount_Term
feature_eng_set$Percent_income_of_loan = 100*feature_eng_set$Income/(feature_eng_set$LoanAmount * 1000)
feature_eng_set$Percent_loan_per_month_income = 100*feature_eng_set$Loan_amout_per_month/feature_eng_set$Income

feature_eng_set0 = feature_eng_set[feature_eng_set$Loan_Status == 0,]
feature_eng_set1 = feature_eng_set[feature_eng_set$Loan_Status == 1,]

feature_eng_set0_newFeatures_res = data.frame(Loan_Status = "Yes",Income = median(feature_eng_set0$Income), Percent_income_of_loan = median(feature_eng_set0$Percent_income_of_loan), Loan_amount_per_month = median(feature_eng_set0$Loan_amout_per_month),Percent_loan_per_month_income = median(feature_eng_set0$Percent_loan_per_month_income))

feature_eng_set1_newFeatures_res = data.frame(Loan_Status = "No",Income = median(feature_eng_set1$Income), Percent_income_of_loan = median(feature_eng_set1$Percent_income_of_loan), Loan_amount_per_month = median(feature_eng_set1$Loan_amout_per_month),Percent_loan_per_month_income = median(feature_eng_set1$Percent_loan_per_month_income))

median_new_features = rbind(feature_eng_set0_newFeatures_res,feature_eng_set1_newFeatures_res)
frame_func(median_new_features)
```


<center><b>Kredyt nie zostal udzielony</b></center>
```{r, echo=FALSE}

feature_eng_set0_newFeatures_sd = data.frame(Loan_Status = "Yes",Income = sd(feature_eng_set0$Income), Percent_income_of_loan = sd(feature_eng_set0$Percent_income_of_loan), Loan_amount_per_month = sd(feature_eng_set0$Loan_amout_per_month),Percent_loan_per_month_income = sd(feature_eng_set0$Percent_loan_per_month_income))

feature_eng_set1_newFeatures_sd = data.frame(Loan_Status = "No",Income = sd(feature_eng_set1$Income), Percent_income_of_loan = sd(feature_eng_set1$Percent_income_of_loan), Loan_amount_per_month = sd(feature_eng_set1$Loan_amout_per_month),Percent_loan_per_month_income = sd(feature_eng_set1$Percent_loan_per_month_income))

median_new_features = rbind(feature_eng_set0_newFeatures_sd,feature_eng_set1_newFeatures_sd)
frame_func(median_new_features)
```

Mozna zauwazyc, ze w wiekszosci przypadkow mediany roznia sie w sposob, ktory mozna uznac za satysfakcjonujacy. Odchylenia w niektorych przypadkach sa juz znacznie rozne, co moze dla zmiennych Income oraz Percent_loan_per_month_income okazac sie pomocny przy wplywie na decyzje modeli.

```{r, echo = FALSE, message=FALSE, warning=FALSE,fig.align = 'center',out.extra='angle=90'}
set.seed(123)
plot1 <- feature_eng_set0 %>% 
            ggplot(aes(x=as.factor(feature_eng_set0$n_pers_income), fill = as.factor(feature_eng_set0$n_pers_income)))+
              geom_histogram(stat = "count")+
              labs(x = "Liczba osob z dochodem")+
              geom_label(stat='count',aes(label=..count..)) +
              theme(legend.title = element_blank())
plot2 <- feature_eng_set1 %>% 
            ggplot(aes(x=as.factor(feature_eng_set1$n_pers_income), fill = as.factor(feature_eng_set1$n_pers_income)))+
              geom_histogram(stat = "count")+
              labs(x = "Liczba os?b z dochodem")+
              geom_label(stat='count',aes(label=..count..)) +
              theme(legend.title =  element_blank())

grid.arrange(plot1, plot2)
```

W licznosciach dla liczby osob posiadajacych dochod widac, ze w przypadku kiedy kredyt zostal udzielony to w wiekszosci przypadkow dwie osoby posiadaly dochod, z kolei kiedy kredyt nie zostal udzielony to licznosci dla obu sytuacji sa praktycznie rowne.

####3.4 Korelacja
```{r, echo = FALSE, warning=FALSE}
zmienne_obj = feature_eng_set[,c(2:12,14:ncol(feature_eng_set))]
korelacja = hetcor(feature_eng_set[,13],zmienne_obj)
korelacja = data.frame(korelacja$correlations[1,])
colnames(korelacja) = "Loan_Status"
korelacja = data.frame(Zmienna = rownames(korelacja)[-1], Korelacja = korelacja[-1,])
frame_func(korelacja)
```

Jak mozna zauwazyc w tabeli powyzej, wiekszosc zmiennych jest slabo skorelowana ze zmienna Loan_Status. Jednak zmienne powstale na podstawie zmiennych ApplicantIncome oraz CoapplicantIncome mogl okazac sie rownie dobre lub nawet lepsze we wplywie na poprawna ocene modelu, ich korelacje sa bliskie lub w niektorych przypadkach nawet slabsze od tych nowo powstalych. Chociaz pomiedzy zmiennymi objaaniajacymi moze dochodzic do wysokiej korelacji, to jednak modelowanie przy pomocy drzew jest na to odporne.

##4. Wybor zbiorow
Po uzupelnianiu wartosci brakujacych roznymi metodami posiadamy 57 zbiorow danych oraz 3 bazowe. Ze wzgledu na ich zbyt duza ilosc, z 57 utworzonych przy pomocy 3 algorytmow uzupelniania danych, wybierzemy tylko 5, ktore pozwola nam osiganac najlepsza skutecznosc predykcji. Wybor zbiorow, ktore najlepiej nadaja sie do predykcji, dokonamy przy pomocy metody Cross Validation (CV) oraz Random Forest (RF).Dzieki CV dla kazdego ze zbiorow danych zostanie utworzone po 6 zbiorow teningowych oraz testowych i accuracy zbioru bedzie liczone jako srednia arytmetyczna wynikow z metody RF. Nastepnie przy pomocy wspolczynnika Giniego zostanie wybrana zmienna o najmniejszym wplywie, ktora usuniemy ze zbioru. Algorytm bedzie powtarzany dla kazdego zbioru danych do momentu, az zostanie 1 zmienna, po czym wybierze on model dla ktorego skutecznosc predykcji byla najwieksza. Wyniki wybranych zbiorow prezentuja sie nastepujaca:
```{r, echo = FALSE, warning=FALSE}
########################################Wybranie zbior?w#######################################)
#Lista na zbiory po usunieciu zmiennych
  noweZbiory = list()
  zbiorki = list()
#Data frame na wyniki acc na podstawie, kt?rego wybrane zostanie 10 zbiorow
  accZbiorow = data.frame(ACC=NA)
  accNajlepsze = data.frame(ACC=NA)
  listaDanych = uzupelnianie_dane
  
for(z in 1:length(listaDanych)) {

  feature_eng_set = listaDanych[[z]]
  
  #Przygotowanie nowych zmiennych
  feature_eng_set$Income = (feature_eng_set$ApplicantIncome + feature_eng_set$CoapplicantIncome)
  feature_eng_set$n_pers_income = ifelse(feature_eng_set$ApplicantIncome >0 & feature_eng_set$CoapplicantIncome >0, 1, 0)
  feature_eng_set$Loan_amout_per_month = (feature_eng_set$LoanAmount * 1000)/feature_eng_set$Loan_Amount_Term
  feature_eng_set$Percent_income_of_loan = 100*feature_eng_set$Income/(feature_eng_set$LoanAmount * 1000)
  feature_eng_set$Percent_loan_per_month_income = 100*feature_eng_set$Loan_amout_per_month/feature_eng_set$Income
  
  
  
  set = feature_eng_set
#Przygotowanie 10 krotnej Cross Validation
wyniki_df<-data.frame("metoda"=rep(0,(ncol(set) - 2)),"wynik"=rep(0,(ncol(set) - 2)), "wynik_treningowy" = rep(0,(ncol(set) - 2)))

 for(i in 1:(ncol(set) - 2)) {
   imps_cv = 0
   acc_rf_all = 0
   #Randomowe ustawienie danych
   set.seed(123)
    set<-set[sample(nrow(set)),]
    
    set.seed(123)
    #Stworz 6 rownych setow
    folds <- cut(seq(1,nrow(set)),breaks=6,labels=FALSE)
     for(j in 1:6){
      #Podzial danych
      set.seed(123)
      testIndexes <- which(folds==j,arr.ind=TRUE)
      trainset <- set[-testIndexes, ]
      testset <- set[testIndexes, ]
      #Test
      set.seed(123)
      model_rf<-randomForest(Loan_Status~.,trainset,ntree=100)
      
      #Sprawdzanie Accuracy
      pred_rf<-predict(model_rf,testset)
      acc_rf<-1 - accuracy(round(pred_rf),testset$Loan_Status)[,3]
      
      #Sprawdzanie istotno?ci zmiennych
      imp_frame = data.frame(model_rf$importance)
      imps_cv = imps_cv + imp_frame
      acc_rf_all = acc_rf_all + acc_rf
      
      #Po wykonaniu CV u?rednij wynik ACC i usu? zmienn? o najmniejszym wp?ywie
      if(j == 6) {
        gini_imp = imps_cv[,1]
        to.remove<-rownames(imps_cv)[c(which.min(gini_imp))]
        wyniki_df[i,]<-c("rf",acc_rf_all/6,to.remove)
        
        zbiorki[[i]] = set
        accZbiorow[i,1] = acc_rf_all/6
        set = set[,-which(names(set) %in% paste(to.remove))]
        }
      #Remove the variable with the lowest decrease in Accuracy (Least relevant variable)
      } 
 }
accNajlepsze[z,1] = max(accZbiorow[,1])
noweZbiory[[z]] = zbiorki[[which.max(accZbiorow[,1])]]
}
  #Wybranie 10 najlepszych zbior?w
zbioryDoBadania = tail(order(accNajlepsze), 5)

#Lista ostatecznie wybranych do badania zbiorow
zbioryBadanie_lita = list()
for(i in 1:5) {
  zbioryBadanie_lita[[i]] = noweZbiory[[zbioryDoBadania[i]]]
}
wynik_wyboruZbiorow = data.frame("Nazwa metody" = rev(unlist(nazwa_metody)[zbioryDoBadania]), "Atrybuty" = rev(unlist(nazwa_atrybutow)[zbioryDoBadania]), "ACC" = rev(accNajlepsze[zbioryDoBadania,]))

frame_func(wynik_wyboruZbiorow)
```

Ponizej natomiast znajduja sie wyniki, ktore przy tej probie osiagnely zbiory bazowe
```{r, echo = FALSE, warning=FALSE}
########################################ACC dla 2 pierwszych bazowych zbiorow#######################################

#Lista na zbiory po usunieciu zmiennych
  noweZbiory = list()
  zbiorki = list()
#Data frame na wyniki acc na podstawie, kt?rego wybrane zostanie 10 zbiorow
  accZbiorow = data.frame(ACC=NA)
  accNajlepsze = data.frame(ACC=NA)
  listaDanych = c(list(lista_dane[[1]]), list(lista_dane[[2]]),list(lista_dane[[3]]))
  
for(z in 1:2) {
  
  feature_eng_set = listaDanych[[z]]
  
  #Przygotowanie nowych zmiennych
  feature_eng_set$Income = (feature_eng_set$ApplicantIncome + feature_eng_set$CoapplicantIncome)
  feature_eng_set$n_pers_income = ifelse(feature_eng_set$ApplicantIncome >0 & feature_eng_set$CoapplicantIncome >0, 1, 0)
  feature_eng_set$Loan_amout_per_month = (feature_eng_set$LoanAmount * 1000)/feature_eng_set$Loan_Amount_Term
  feature_eng_set$Percent_income_of_loan = 100*feature_eng_set$Income/(feature_eng_set$LoanAmount * 1000)
  feature_eng_set$Percent_loan_per_month_income = 100*feature_eng_set$Loan_amout_per_month/feature_eng_set$Income
  
  
  
  set = feature_eng_set
#Przygotowanie 10 krotnej Cross Validation
wyniki_df<-data.frame("metoda"=rep(0,(ncol(set) - 2)),"wynik"=rep(0,(ncol(set) - 2)), "wynik_treningowy" = rep(0,(ncol(set) - 2)))

 for(i in 1:(ncol(set) - 2)) {
   imps_cv = 0
   acc_rf_all = 0
   #Randomowe ustawienie danych
   set.seed(123)
    set<-set[sample(nrow(set)),]
    
    set.seed(123)
    #Stworz 6 rownych setow
    folds <- cut(seq(1,nrow(set)),breaks=6,labels=FALSE)
     for(j in 1:6){
      #Podzial danych
      set.seed(123)
      testIndexes <- which(folds==j,arr.ind=TRUE)
      trainset <- set[-testIndexes, ]
      testset <- set[testIndexes, ]
      #Test
      set.seed(123)
      model_rf<-randomForest(Loan_Status~.,trainset,ntree=100)
      
      #Sprawdzanie Accuracy
      pred_rf<-predict(model_rf,testset)
      conf_rf<-table(round(pred_rf),testset$Loan_Status)
      acc_rf<-(conf_rf[1,1]+conf_rf[2,2])/sum(conf_rf)
      
      #Sprawdzanie istotno?ci zmiennych
      imp_frame = data.frame(model_rf$importance)
      imps_cv = imps_cv + imp_frame
      acc_rf_all = acc_rf_all + acc_rf
      
      #Po wykonaniu CV u?rednij wynik ACC i usu? zmienn? o najmniejszym wp?ywie
      if(j == 6) {
        gini_imp = imps_cv[,1]
        to.remove<-rownames(imps_cv)[c(which.min(gini_imp))]
        wyniki_df[i,]<-c("rf",acc_rf_all/6,to.remove)
        
        zbiorki[[i]] = set
        accZbiorow[i,1] = acc_rf_all/6
        set = set[,-which(names(set) %in% paste(to.remove))]
        }
      #Remove the variable with the lowest decrease in Accuracy (Least relevant variable)
      } 
 }
accNajlepsze[z,1] = max(accZbiorow[,1])
noweZbiory[[z]] = zbiorki[[which.max(accNajlepsze[,1])]]
}
```

```{r, echo = FALSE, warning=FALSE}
########################################ACC dla 2 pierwszych bazowych zbiorow#######################################
for(z in 3) {
  
  feature_eng_set = listaDanych[[z]]

  
  set = feature_eng_set
#Przygotowanie 10 krotnej Cross Validation
wyniki_df<-data.frame("metoda"=rep(0,1),"wynik"=rep(0,1), "wynik_treningowy" = rep(0,1))

   imps_cv = 0
   acc_rf_all = 0
   #Randomowe ustawienie danych
   set.seed(123)
    set<-set[sample(nrow(set)),]
    
    set.seed(123)
    #Stworz 6 rownych setow
    folds <- cut(seq(1,nrow(set)),breaks=6,labels=FALSE)
     for(j in 1:6){
      #Podzial danych
      set.seed(123)
      testIndexes <- which(folds==j,arr.ind=TRUE)
      trainset <- set[-testIndexes, ]
      testset <- set[testIndexes, ]
      #Test
      set.seed(123)
      model_rf<-randomForest(Loan_Status~.,trainset,ntree=100)
      
      #Sprawdzanie Accuracy
      pred_rf<-predict(model_rf,testset)
      conf_rf<-table(round(pred_rf),testset$Loan_Status)
      acc_rf<-(conf_rf[1,1]+conf_rf[2,2])/sum(conf_rf)
      
      #Sprawdzanie istotno?ci zmiennych
      imp_frame = data.frame(model_rf$importance)
      imps_cv = imps_cv + imp_frame
      acc_rf_all = acc_rf_all + acc_rf
      
      #Po wykonaniu CV u?rednij wynik ACC i usu? zmienn? o najmniejszym wp?ywie
      if(j == 6) {
        zbiorki[[z]] = set
        accNajlepsze[z,1] = acc_rf_all/6
        }
      #Remove the variable with the lowest decrease in Accuracy (Least relevant variable)
      } 
  }


  
    #Wybranie 10 najlepszych zbior?w
zbioryBazowe = tail(order(accNajlepsze), 3)

#Lista ostatecznie wybranych do badania zbiorow
zbioryBazowe_lita = list()
for(i in 1:3) {
  zbioryBazowe_lita[[i]] = zbiorki[[zbioryBazowe[i]]]
}
accNajlepsze[zbioryBazowe,]
nazw = c("NA - remove", "KNN - k=6", "CreditHist - k = 6")
frame_func(data.frame("Metoda"= rev(nazw[zbioryBazowe]), "ACC" = rev(accNajlepsze[zbioryBazowe,])))
```
##5. Dobor metody predykcji

W celu wybrania najlepszej metody przewidujacej czy osoba otrzyma kredyt w banku posluzymy sie tak jak w poprzednim przypadku metoda Cross Validation. Z wybranych metod, jakimi są Random Forest, GBM, Regresja logistyczna, QDA, LDA, XGBoost, Boosting oraz KNN, wybierzemy tę która pozwoli nam na osiągnięcie najlepszego rezultatu dla jednego z wczesniej wybranych zbiorów danych

```{r, warning=FALSE, message=FALSE}
wszystkie_zbiory = c(zbioryBadanie_lita,zbioryBazowe_lita)
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
#wektory sprawdzanych parametrów
ntree_v<-1:17
mtry_v<-1:10
rf_df<-cbind("method"=rep("rf",nrow(expand.grid(ntree_v, mtry_v))),"hp"=paste0("ntree=",expand.grid(ntree_v, mtry_v)[,1],",","mtry=",expand.grid(ntree_v, mtry_v)[,2]))
k_v<-1:16
knn_df<-cbind("method"=rep("knn",nrow(expand.grid(k_v))),"hp"=paste0("k=",expand.grid(k_v)[,1]))
n.trees_v<-c(500,1000,6000,10000)
shrinkage_v<-c(0.015,0.025,0.04,0.055)
interaction.depth_v<-c(2,5,7)
gbm_df<-cbind("method"=rep("gbm",nrow(expand.grid(n.trees_v,shrinkage_v,interaction.depth_v))),"distribution"=rep("distribution='gaussian'",nrow(expand.grid(n.trees_v,shrinkage_v,interaction.depth_v))),"cv.folds"=rep("cv.folds=2",nrow(expand.grid(n.trees_v,shrinkage_v,interaction.depth_v))),"hp"=paste0("n.trees=",expand.grid(n.trees_v,shrinkage_v,interaction.depth_v)[,1],",","shrinkage=",expand.grid(n.trees_v,shrinkage_v,interaction.depth_v)[,2],",","interaction.depth=",expand.grid(n.trees_v,shrinkage_v,interaction.depth_v)[,3]))
hp_v<-c(paste0("list(",rf_df[,2],")"),paste0("list(",knn_df[,2],")"),paste0("list(",gbm_df[,2],",",gbm_df[,3],",",gbm_df[,4],")"))
method_v<-c(rf_df[,1],knn_df[,1],gbm_df[,1])
acc_list<-list()
for (i in 1:length(hp_v)) {
  method<-method_v[i]
  arg_list<-eval(parse(text=hp_v[i]))
  acc<-cv_pred(5,wszystkie_zbiory,method=method,arg_list=arg_list)
  acc_list[i]<-acc
}
best_acc<-max(unlist(acc_list))
best_parameters<-c(rf_df[,2],knn_df[,2],gbm_df[,4])[unlist(acc_list)==best_acc]
best_method<-method_v[unlist(acc_list)==best_acc]
#data.frame("best method"=best_method,"best_parameters"=best_parameters,"best_acc"=best_acc) %>% kable()
data.frame(best_method,best_parameters,best_acc) %>% kable()
```

```{r, message=FALSE, warning=FALSE}
################XGBoost###############
wyniki_df<-data.frame("NumerZbioru"=rep(0,length(wszystkie_zbiory)),"wynik"=rep(0,length(wszystkie_zbiory)), "wynik_testowy" = rep(0,length(wszystkie_zbiory)))
for(i in 1:length(wszystkie_zbiory))
{
  set.seed(123)
  set = wszystkie_zbiory[[i]]
  #Zamiana danych treningowych i testowych na data table
  loanik = which(colnames(trainset)) == "Loan_Status"
  ###Podzial danych
  set.seed(123)
  train_ind<-sample(1:nrow(set),floor(0.75*nrow(set)))
  
  trainset<-set[train_ind,]
  testset<-set[-train_ind,] 
  
  traindata <- data.table(trainset)
  validationdata <- data.table(testset)
  
  numCol <- ncol(traindata)
  
  #Zamiana danych data table na Matrix z funckji xgboost
  trainx <- Matrix(data.matrix(traindata[,-c("Loan_Status"),with=FALSE]), sparse=TRUE)
  trainy <- as.numeric(traindata$Loan_Status)
  inputValid <- Matrix(data.matrix(validationdata[,c(1:numCol),with=FALSE]), sparse=TRUE)
  
  #Dob?r parametr?w
  
  xgbGrid <- expand.grid(
    nrounds = c(10000),
    max_depth = seq(3,6,by=1),
    eta = seq(0.03,0.05,by=0.01),
    gamma = seq(0,1,by=1),
    colsample_bytree = seq(0.4,0.6,by = 0.1),
    min_child_weight = seq(1,1,by = 0.5),
    subsample = seq(0.4,0.6,by = 0.1),
    iterations = seq(20,50, by = 1)
  )
  
  rmseErrorsHyperparameters <- apply(xgbGrid, 1, function(parameterList){
    #Extract Parameters to test
    currentSubsampleRate <- parameterList[["subsample"]]
    currentColsampleRate <- parameterList[["colsample_bytree"]]
    currentMin_Child_Weight <- parameterList[["min_child_weight"]]
    currentGamma <- parameterList[["gamma"]]
    currentEta <- parameterList[["eta"]]
    currentMax_Depth <- parameterList[["max_depth"]]
    currentNrounds <- parameterList[["nrounds"]]
    currentIteration <- parameterList[["iterations"]]
    
    params <- list(objective = "binary:logistic", 
                   #booster = "gbtree", 
                   #eta = 2/currentNrounds,
                   eta = currentEta, 
                   gamma = currentGamma, 
                   max_depth = currentMax_Depth, 
                   min_child_weight = currentMin_Child_Weight, 
                   subsample = currentSubsampleRate, 
                   colsample_bytree = currentColsampleRate)
    
    set.seed(123)
    xgbcv <- xgb.cv(params = params, 
                    data = trainx, label = trainy,
                    nrounds = currentNrounds, nfold = 5, 
                    showsd = T, stratified = T, early_stopping_rounds = 25, maximize = F)
    
    test_error <- xgbcv$evaluation_log$test_error_mean[xgbcv$best_iteration]
    train_error <- xgbcv$evaluation_log$train_error_mean[xgbcv$best_iteration]
    
    return(c(test_error, train_error, currentSubsampleRate, currentColsampleRate,
             currentMin_Child_Weight,currentGamma,currentEta,
             currentMax_Depth,currentNrounds,xgbcv$best_iteration))
    
  })
  
  simTrain <- as.data.frame(t(rmseErrorsHyperparameters))
  colnames(simTrain) <- c('Train_Error','Test_Error','SubSampleRate','ColSampleRate',
                          'MinChildWgt','Gamma','ETA','MaxDepth','NRound', 'Iteration')
  simTrain$Diff <- simTrain$Test_Error - simTrain$Train_Error
  bestTrain <- simTrain[which.max(simTrain[,1]),]
  bestTrain
  best_iteration <- bestTrain$Iteration
  
  params <- list(objective = "binary:logistic", 
                 #booster = "gbtree", 
                 eta = bestTrain$ETA, 
                 gamma = bestTrain$Gamma, 
                 max_depth = bestTrain$MaxDepth, 
                 min_child_weight = bestTrain$MinChildWgt, 
                 subsample = bestTrain$SubSampleRate, 
                 colsample_bytree = bestTrain$ColSampleRate
  )
  
  
  #Training
  set.seed(123)
  xgbmodel_train <- xgboost(params = params, data = trainx, label = trainy, nround = best_iteration)
  
  xgBoostValidation_train <- predict(xgbmodel_train,trainx)
  
  conf_xgboost_train<-table(round(xgBoostValidation_train),trainy)
  acc_xgboost_train<-(conf_xgboost_train[1,1]+conf_xgboost_train[2,2])/sum(conf_xgboost_train)
  
  #Test
  set.seed(123)
  xgbmodel <- xgboost(params = params, data = trainx, label = trainy, nrounds = best_iteration)
  
  inputValid <- Matrix(data.matrix(validationdata[,1:numCol,with=FALSE]), sparse=TRUE)
  xgBoostValidation <- predict(xgbmodel,inputValid[,loanik])
  
  conf_xgboost<-table(round(xgBoostValidation),inputValid[,loanik])
  acc_xgboost<-(conf_xgboost[1,1]+conf_xgboost[2,2])/sum(conf_xgboost)
  
  wyniki_df[i,]<-c(bestTrain[,1],acc_xgboost,acc_xgboost_train)
  
}
best_acc<-max(wyniki_df[,2])
best_set<-wyniki_df[wyniki_df[,2]=best_acc,]
data.frame("best_set"=best_set,"best_acc"=best_acc) %>% kable()
```

```{r, warning=FALSE, message=FALSE}

```

```{r, warning=FALSE, message=FALSE}

```

```{r, warning=FALSE, message=FALSE}

```
